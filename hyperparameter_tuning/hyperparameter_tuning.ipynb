{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning using Azure ML service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper-parameters of methods presented in this tutorial are tuned using Hyperdrive, a feature of Azure Machine Learning (Azure ML) service. Before running this notebook, please follow instructions in [configuration notebook](../configuration.ipynb) and provision Azure ML workspace.\n",
    "\n",
    "The running time depends on the size of your Azure ML cluster and the method being tuned.\n",
    "\n",
    "This notebook is used to tune several approaches:\n",
    "- Feed-forward network multi-step multivariate approach (`ff_multistep_config.json`)\n",
    "- RNN multi-step approach (`rnn_multistep_config.json`)\n",
    "- RNN teacher forcing approach (`rnn_teacher_forcing_config.json`)\n",
    "- RNN encoder decoder approach (`rnn_encoder_decoder_config.json`)\n",
    "\n",
    "Each of these use cases is defined in a json configuration file listed above in parenthesis. To run a specific approach, please specify the appropriate configuration file in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import azureml\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.hyperdrive import (\n",
    "    RandomParameterSampling,\n",
    "    HyperDriveConfig,\n",
    "    PrimaryMetricGoal,\n",
    "    choice,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify and import configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please specify the configuration file for this notebook run. Configuration file is a json file containing the following parameters that will be used by the notebook:\n",
    "- EXPERIMENT_NAME\n",
    "- CLUSTER_NAME\n",
    "- SCRIPT_DIR\n",
    "- SCRIPT_NAME\n",
    "- SCRIPT_PARAMS\n",
    "- HYPER_PARAMS\n",
    "- MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"ff_multistep_config.json\"\n",
    "\n",
    "try:\n",
    "    with open(config_file) as f:\n",
    "        params = json.load(f)\n",
    "except IOError:\n",
    "    print(\"Config file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified notebook parameters:\n",
      "\n",
      " {'EXPERIMENT_NAME': 'ff-multistep', 'CLUSTER_NAME': 'gpucluster', 'SCRIPT_DIR': './FF_multi_step_multivariate', 'SCRIPT_NAME': 'FF_multi_step_multivariate.py', 'SCRIPT_PARAMS': {'--latent-dim': 5, '--hidden-layers': 2, '--batch-size': 16, '--T': 72, '--learning-rate': 0.01, '--alpha': 0.1}, 'HYPER_PARAMS': {'--latent-dim': [5, 10, 15], '--hidden-layers': [1, 2, 3], '--batch-size': [8, 16, 32], '--T': [72, 168, 336], '--learning-rate': [0.01, 0.001, 0.0001], '--alpha': [0.1, 0.001, 0]}, 'MODEL_NAME': 'ff-multistep-best'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Specified notebook parameters:\\n\\n\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the configuration notebook. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using Azure ML SDK Version:  1.0.33\n"
     ]
    }
   ],
   "source": [
    "# check core SDK version number\n",
    "print(\"You are using Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: vapaunic-dnntut-ws\n",
      "Azure region: westeurope\n",
      "Subscription id: a61eb99b-265d-430b-91c8-911f86ae9be1\n",
      "Resource group: vapaunic-aml-rg\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(\n",
    "        \"Workspace name: \" + ws.name,\n",
    "        \"Azure region: \" + ws.location,\n",
    "        \"Subscription id: \" + ws.subscription_id,\n",
    "        \"Resource group: \" + ws.resource_group,\n",
    "        sep=\"\\n\",\n",
    "    )\n",
    "except:\n",
    "    print(\n",
    "        \"Workspace not accessible. Change your parameters or create a new workspace using configuration.ipynb notebook.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an Azure ML experiment. All executed runs will be recorded under this experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name=params[\"EXPERIMENT_NAME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data and scripts to default datastore \n",
    "A [datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data) is a place where data can be stored that is then made accessible to a Run either by means of mounting or copying the data to the compute target. A datastore can either be backed by an Azure Blob Storage or and Azure File Share (ADLS will be supported in the future). For simple data handling, each workspace provides a default datastore that can be used, in case the data is not already in Blob Storage or File Share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, we will upload the training and test set into the workspace's default datastore, which we will then later be mount on an AmlCompute cluster for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../data/GEFCom2014.zip\n",
      "Uploaded ../data/GEFCom2014.zip, 1 files out of an estimated total of 1\n",
      "Uploading ../common/extract_data.py\n",
      "Uploading ../common/utils.py\n",
      "Uploaded ../common/utils.py, 1 files out of an estimated total of 2\n",
      "Uploaded ../common/extract_data.py, 2 files out of an estimated total of 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_0417352ec970449497fba70e5db678d7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.upload_files(\n",
    "    files=[\"../data/GEFCom2014.zip\"],\n",
    "    target_path=\"energy\",\n",
    "    overwrite=True,\n",
    "    show_progress=True,\n",
    ")\n",
    "ds.upload_files(\n",
    "    files=[\"../common/extract_data.py\", \"../common/utils.py\"],\n",
    "    target_path=\"common\",\n",
    "    overwrite=True,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you create `AmlCompute` as your training compute resource.\n",
    "\n",
    "If we could not find the cluster with the given name, then we will create a new cluster here. We will create an `AmlCompute` cluster of `STANDARD_NC6` GPU VMs. This process is broken down into 3 steps:\n",
    "1. create the configuration (this step is local and only takes a second)\n",
    "2. create the cluster (this step will take about **20 seconds**)\n",
    "3. provision the VMs to bring the cluster to the initial size (of 1 in this case). This step will take about **3-5 minutes** and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-05-08T22:38:42.061000+00:00', 'errors': None, 'creationTime': '2019-04-30T12:55:55.065120+00:00', 'modifiedTime': '2019-04-30T14:56:02.842868+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT1000S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "# choose a name for your cluster\n",
    "cluster_name = params[\"CLUSTER_NAME\"]\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing compute target\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_NC6\", min_nodes=0, max_nodes=4\n",
    "    )\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20\n",
    "    )\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster.\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure ML concepts  \n",
    "Please note the following three things in the code below:\n",
    "1. The script accepts arguments using the argparse package. In this case there is one argument `--datadir` which specifies the file system folder in which the script can find the MNIST data\n",
    "```\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--datadir')\n",
    "```\n",
    "2. The script is accessing the Azure ML `Run` object by executing `run = Run.get_context()`. Further down the script is using the `run` to report the loss and accuracy at the end of each epoch via callback.\n",
    "```\n",
    "    run.log('Loss', log['loss'])\n",
    "    run.log('Accuracy', log['acc'])\n",
    "```\n",
    "3. When running the script on Azure ML, you can write files out to a folder `./outputs` that is relative to the root directory. This folder is specially tracked by Azure ML in the sense that any files written to that folder during script execution on the remote target will be picked up by Run History; these files (known as artifacts) will be available as part of the run history record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow estimator & add Keras\n",
    "Next, we construct an `azureml.train.dnn.TensorFlow` estimator object, use the `gpucluster` as compute target, and pass the mount-point of the datastore to the training code as a parameter.\n",
    "The TensorFlow estimator is providing a simple way of launching a TensorFlow training job on a compute target. It will automatically provide a docker image that has TensorFlow installed. In this case, we add `keras` package (for the Keras framework), and additional packages required for running the training script on the compute target.\n",
    "\n",
    "We also specify `entry_script` as one of the parameters. This is the script that is going to be executed on the compute target. Please examine the script for better understanding of the training process, and the metrics that are being logged. You'll notice that for each training run, we execute `N_EXPERIMENTS` runs, in order to run the experiment with different weight initializations. We noticed that there is a good variation in obtained metrics (validation and test MAPE) across the experiments, so we use average validation MAPE over all `N_EXPERIMENTS` as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "script_params = params[\"SCRIPT_PARAMS\"]\n",
    "script_params.update(\n",
    "    {\n",
    "        \"--datadir\": ds.path(\"energy\").as_mount(),\n",
    "        \"--scriptdir\": ds.path(\"common\").as_mount(),\n",
    "    }\n",
    ")\n",
    "\n",
    "est = TensorFlow(\n",
    "    source_directory=params[\"SCRIPT_DIR\"],\n",
    "    script_params=script_params,\n",
    "    compute_target=compute_target,\n",
    "    conda_packages=[\"pandas\", \"numpy\"],\n",
    "    pip_packages=[\"keras\", \"matplotlib\", \"scikit-learn\", \"xlrd\", \"azureml-sdk\"],\n",
    "    entry_script=params[\"SCRIPT_NAME\"],\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to run\n",
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b535b0c12d749e6902b5e94a2e6deba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation MAPEs': [0.13058066798581017,\n",
       "  0.13081573910183378,\n",
       "  0.12988554727700022,\n",
       "  0.1296813256210751,\n",
       "  0.12975195149580637],\n",
       " 'test MAPEs': [0.23173711412391518,\n",
       "  0.21802933885413006,\n",
       "  0.23711992379906563,\n",
       "  0.23274828174229842,\n",
       "  0.23482239356161924],\n",
       " 'meanValidationMAPE': 0.13014304629630513,\n",
       " 'meanTestMAPE': 0.2308914104162057}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/55_batchai_execution.txt',\n",
       " 'azureml-logs/60_control_log.txt',\n",
       " 'azureml-logs/80_driver_log.txt',\n",
       " 'azureml-logs/azureml.log',\n",
       " 'outputs/model/bestmodel_exp3.h5',\n",
       " 'outputs/model/bestmodel_exp3.json']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "We have trained the model with one set of hyperparameters, now let's how we can do hyperparameter tuning by launching multiple runs on the cluster. First let's define the parameter space using random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = dict()\n",
    "\n",
    "for key, value in params[\"HYPER_PARAMS\"].items():\n",
    "    hparams[key] = choice(value)\n",
    "\n",
    "ps = RandomParameterSampling(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new estimator without the above parameters since they will be passed in later by Hyperdrive configuration. Note we still need to keep the `--datadir` and `--scriptdir` parameters since they are not hyperparamters we will sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "est = TensorFlow(\n",
    "    source_directory=params[\"SCRIPT_DIR\"],\n",
    "    script_params={\n",
    "        \"--datadir\": ds.path(\"energy\").as_mount(),\n",
    "        \"--scriptdir\": ds.path(\"common\").as_mount(),\n",
    "    },\n",
    "    compute_target=compute_target,\n",
    "    conda_packages=[\"pandas\", \"numpy\"],\n",
    "    pip_packages=[\"keras\", \"matplotlib\", \"scikit-learn\", \"xlrd\", \"azureml-sdk\"],\n",
    "    entry_script=params[\"SCRIPT_NAME\"],\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to configure a run configuration object, and specify the primary metric `meanValidationMAPE` that's recorded in your training runs. We also want to tell the service that we are looking to minimize this value. We also set the number of total runs, and maximal concurrent job count, which should be up to the the number of nodes in our computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdc = HyperDriveConfig(\n",
    "    estimator=est,\n",
    "    hyperparameter_sampling=ps,\n",
    "    primary_metric_name=\"meanValidationMAPE\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "    max_total_runs=50,\n",
    "    max_concurrent_runs=4,\n",
    "    # max_duration_minutes=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = exp.submit(config=hdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a run history widget to show the progress. Be patient as this might take a while to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6787646a663419ea136c04e150c449f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(hdr).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and register the best model\n",
    "When all the jobs finish, we can find out the one that has the lowest mean validation MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--datadir', '$AZUREML_DATAREFERENCE_74e41a06add54178b4a71afca5b5aed4', '--scriptdir', '$AZUREML_DATAREFERENCE_2dff5db2615f45f890a92de56476be57', '--T', '168', '--alpha', '0', '--batch-size', '8', '--hidden-layers', '1', '--latent-dim', '10', '--learning-rate', '0.0001']\n"
     ]
    }
   ],
   "source": [
    "best_run = hdr.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()[\"runDefinition\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation MAPEs': [0.00237633829334906,\n",
       "  0.0025241895691983196,\n",
       "  0.0023787959905651706,\n",
       "  0.002544753123786197,\n",
       "  0.0022434681519775445],\n",
       " 'test MAPEs': [0.042385739896449295,\n",
       "  0.04368646865939124,\n",
       "  0.04232069881219596,\n",
       "  0.04289407423044128,\n",
       "  0.04115717144975747],\n",
       " 'meanValidationMAPE': 0.002413509025775258,\n",
       " 'meanTestMAPE': 0.042488830609647046}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's list the model files uploaded during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/55_batchai_execution.txt', 'azureml-logs/60_control_log.txt', 'azureml-logs/80_driver_log.txt', 'azureml-logs/azureml.log', 'outputs/model/bestmodel_exp4.h5', 'outputs/model/bestmodel_exp4.json']\n"
     ]
    }
   ],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then register the folder (and all files in it) as a model under the workspace model registry for future deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name=params[\"MODEL_NAME\"], model_path='outputs/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnntutorial",
   "language": "python",
   "name": "dnntutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
